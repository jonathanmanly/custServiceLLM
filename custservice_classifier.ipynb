{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate\n",
    "!pip install -U transformers\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import re\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tinyTest=False\n",
    "\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/bitext/customer-support-llm-chatbot-training-dataset/main/data/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "\n",
    "    csv_data = io.BytesIO(response.content)\n",
    "    df = pd.read_csv(csv_data)\n",
    "    print(df.head())  # Display the first few rows of the DataFrame\n",
    "else:\n",
    "    print(\"Failed to download the CSV file.\")\n",
    "\n",
    "print(\"Downloaded \",len(df),\"rows\")\n",
    "\n",
    "df=df.drop('flags',axis=1)\n",
    "origdf =df.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_names = [\"Aberdeen\", \"Abilene\", \"Akron\", \"Albany\", \"Albuquerque\", \"Alexandria\", \"Allentown\", \"Amarillo\", \"Anaheim\", \"Anchorage\", \"Ann Arbor\", \"Antioch\", \"Apple Valley\", \"Appleton\", \"Arlington\", \"Arvada\", \"Asheville\", \"Athens\", \"Atlanta\", \"Atlantic City\", \"Augusta\", \"Aurora\", \"Austin\", \"Bakersfield\", \"Baltimore\", \"Barnstable\", \"Baton Rouge\", \"Beaumont\", \"Bel Air\", \"Bellevue\", \"Berkeley\", \"Bethlehem\", \"Billings\", \"Birmingham\", \"Bloomington\", \"Boise\", \"Boise City\", \"Bonita Springs\", \"Boston\", \"Boulder\", \"Bradenton\", \"Bremerton\", \"Bridgeport\", \"Brighton\", \"Brownsville\", \"Bryan\", \"Buffalo\", \"Burbank\", \"Burlington\", \"Cambridge\", \"Canton\", \"Cape Coral\", \"Carrollton\", \"Cary\", \"Cathedral City\", \"Cedar Rapids\", \"Champaign\", \"Chandler\", \"Charleston\", \"Charlotte\", \"Chattanooga\", \"Chesapeake\", \"Chicago\", \"Chula Vista\", \"Cincinnati\", \"Clarke County\", \"Clarksville\", \"Clearwater\", \"Cleveland\", \"College Station\", \"Colorado Springs\", \"Columbia\", \"Columbus\", \"Concord\", \"Coral Springs\", \"Corona\", \"Corpus Christi\", \"Costa Mesa\", \"Dallas\", \"Daly City\", \"Danbury\", \"Davenport\", \"Davidson County\", \"Dayton\", \"Daytona Beach\", \"Deltona\", \"Denton\", \"Denver\", \"Des Moines\", \"Detroit\", \"Downey\", \"Duluth\", \"Durham\", \"El Monte\", \"El Paso\", \"Elizabeth\", \"Elk Grove\", \"Elkhart\", \"Erie\", \"Escondido\", \"Eugene\", \"Evansville\", \"Fairfield\", \"Fargo\", \"Fayetteville\", \"Fitchburg\", \"Flint\", \"Fontana\", \"Fort Collins\", \"Fort Lauderdale\", \"Fort Smith\", \"Fort Walton Beach\", \"Fort Wayne\", \"Fort Worth\", \"Frederick\", \"Fremont\", \"Fresno\", \"Fullerton\", \"Gainesville\", \"Garden Grove\", \"Garland\", \"Gastonia\", \"Gilbert\", \"Glendale\", \"Grand Prairie\", \"Grand Rapids\", \"Grayslake\", \"Green Bay\", \"GreenBay\", \"Greensboro\", \"Greenville\", \"Gulfport-Biloxi\", \"Hagerstown\", \"Hampton\", \"Harlingen\", \"Harrisburg\", \"Hartford\", \"Havre de Grace\", \"Hayward\", \"Hemet\", \"Henderson\", \"Hesperia\", \"Hialeah\", \"Hickory\", \"High Point\", \"Hollywood\", \"Honolulu\", \"Houma\", \"Houston\", \"Howell\", \"Huntington\", \"Huntington Beach\", \"Huntsville\", \"Independence\", \"Indianapolis\", \"Inglewood\", \"Irvine\", \"Irving\", \"Jackson\", \"Jacksonville\", \"Jefferson\", \"Jersey City\", \"Johnson City\", \"Joliet\", \"Kailua\", \"Kalamazoo\", \"Kaneohe\", \"Kansas City\", \"Kennewick\", \"Kenosha\", \"Killeen\", \"Kissimmee\", \"Knoxville\", \"Lacey\", \"Lafayette\", \"Lake Charles\", \"Lakeland\", \"Lakewood\", \"Lancaster\", \"Lansing\", \"Laredo\", \"Las Cruces\", \"Las Vegas\", \"Layton\", \"Leominster\", \"Lewisville\", \"Lexington\", \"Lincoln\", \"Little Rock\", \"Long Beach\", \"Lorain\", \"Los Angeles\", \"Louisville\", \"Lowell\", \"Lubbock\", \"Macon\", \"Madison\", \"Manchester\", \"Marina\", \"Marysville\", \"McAllen\", \"McHenry\", \"Medford\", \"Melbourne\", \"Memphis\", \"Merced\", \"Mesa\", \"Mesquite\", \"Miami\", \"Milwaukee\", \"Minneapolis\", \"Miramar\", \"Mission Viejo\", \"Mobile\", \"Modesto\", \"Monroe\", \"Monterey\", \"Montgomery\", \"Moreno Valley\", \"Murfreesboro\", \"Murrieta\", \"Muskegon\", \"Myrtle Beach\", \"Naperville\", \"Naples\", \"Nashua\", \"Nashville\", \"New Bedford\", \"New Haven\", \"New London\", \"New Orleans\", \"New York\", \"New York City\", \"Newark\", \"Newburgh\", \"Newport News\", \"Norfolk\", \"Normal\", \"Norman\", \"North Charleston\", \"North Las Vegas\", \"North Port\", \"Norwalk\", \"Norwich\", \"Oakland\", \"Ocala\", \"Oceanside\", \"Odessa\", \"Ogden\", \"Oklahoma City\", \"Olathe\", \"Olympia\", \"Omaha\", \"Ontario\", \"Orange\", \"Orem\", \"Orlando\", \"Overland Park\", \"Oxnard\", \"Palm Bay\", \"Palm Springs\", \"Palmdale\", \"Panama City\", \"Pasadena\", \"Paterson\", \"Pembroke Pines\", \"Pensacola\", \"Peoria\", \"Philadelphia\", \"Phoenix\", \"Pittsburgh\", \"Plano\", \"Pomona\", \"Pompano Beach\", \"Port Arthur\", \"Port Orange\", \"Port Saint Lucie\", \"Port St. Lucie\", \"Portland\", \"Portsmouth\", \"Poughkeepsie\", \"Providence\", \"Provo\", \"Pueblo\", \"Punta Gorda\", \"Racine\", \"Raleigh\", \"Rancho Cucamonga\", \"Reading\", \"Redding\", \"Reno\", \"Richland\", \"Richmond\", \"Richmond County\", \"Riverside\", \"Roanoke\", \"Rochester\", \"Rockford\", \"Roseville\", \"Round Lake Beach\", \"Sacramento\", \"Saginaw\", \"Saint Louis\", \"Saint Paul\", \"Saint Petersburg\", \"Salem\", \"Salinas\", \"Salt Lake City\", \"San Antonio\", \"San Bernardino\", \"San Buenaventura\", \"San Diego\", \"San Francisco\", \"San Jose\", \"Santa Ana\", \"Santa Barbara\", \"Santa Clara\", \"Santa Clarita\", \"Santa Cruz\", \"Santa Maria\", \"Santa Rosa\", \"Sarasota\", \"Savannah\", \"Scottsdale\", \"Scranton\", \"Seaside\", \"Seattle\", \"Sebastian\", \"Shreveport\", \"Simi Valley\", \"Sioux City\", \"Sioux Falls\", \"South Bend\", \"South Lyon\", \"Spartanburg\", \"Spokane\", \"Springdale\", \"Springfield\", \"St. Louis\", \"St. Paul\", \"St. Petersburg\", \"Stamford\", \"Sterling Heights\", \"Stockton\", \"Sunnyvale\", \"Syracuse\", \"Tacoma\", \"Tallahassee\", \"Tampa\", \"Temecula\", \"Tempe\", \"Thornton\", \"Thousand Oaks\", \"Toledo\", \"Topeka\", \"Torrance\", \"Trenton\", \"Tucson\", \"Tulsa\", \"Tuscaloosa\", \"Tyler\", \"Utica\", \"Vallejo\", \"Vancouver\", \"Vero Beach\", \"Victorville\", \"Virginia Beach\", \"Visalia\", \"Waco\", \"Warren\", \"Washington\", \"Waterbury\", \"Waterloo\", \"West Covina\", \"West Valley City\", \"Westminster\", \"Wichita\", \"Wilmington\", \"Winston\", \"Winter Haven\", \"Worcester\", \"Yakima\", \"Yonkers\", \"York\", \"Youngstown\"]\n",
    "country_names = [\n",
    "    \"United States\",    # North America\n",
    "    \"Canada\",           # North America\n",
    "    \"Mexico\",           # North America\n",
    "    \"United Kingdom\",   # Europe\n",
    "    \"Germany\",          # Europe\n",
    "    \"France\",           # Europe\n",
    "    \"Spain\",            # Europe\n",
    "    \"Italy\",            # Europe\n",
    "    \"Netherlands\",      # Europe\n",
    "    \"Sweden\"            # Europe\n",
    "]\n",
    "\n",
    "currency_symbols = [\n",
    "    \"$\", \n",
    "    \"Â£\"\n",
    "]\n",
    "\n",
    "last_names = [\n",
    "    \"Smith\",\n",
    "    \"Johnson\",\n",
    "    \"Williams\",\n",
    "    \"Brown\",\n",
    "    \"Jones\",\n",
    "    \"Garcia\",\n",
    "    \"Miller\",\n",
    "    \"Davis\",\n",
    "    \"Rodriguez\",\n",
    "    \"Martinez\"\n",
    "]\n",
    "\n",
    "first_names = [\n",
    "    \"James\",\n",
    "    \"John\",\n",
    "    \"Robert\",\n",
    "    \"Michael\",\n",
    "    \"William\",\n",
    "    \"David\",\n",
    "    \"Richard\",\n",
    "    \"Joseph\",\n",
    "    \"Charles\",\n",
    "    \"Thomas\",\n",
    "    \"Daniel\",\n",
    "    \"Matthew\",\n",
    "    \"Jennifer\",\n",
    "    \"Jessica\",\n",
    "    \"Ashley\",\n",
    "    \"Sarah\",\n",
    "    \"Emily\",\n",
    "    \"Samantha\",\n",
    "    \"Elizabeth\",\n",
    "    \"Emma\"\n",
    "]\n",
    "\n",
    "\n",
    "accounts =['Checking','Savings','Spending','Prepaid']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetsToFill = df.instruction.str.extract(r'\\{\\{([^}]*)\\}\\}')\n",
    "targetsToFill.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['instruction']=df.instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[['category','intent']].value_counts()\n",
    "\n",
    "labelNames = pd.DataFrame(df['intent'].value_counts()).reset_index().drop(\"intent\",axis=1)\n",
    "labelNames.columns=['labelNames']\n",
    "labelDict = labelNames.to_dict()['labelNames']\n",
    "labelDict = {v: k for k, v in labelDict.items()}\n",
    "reverseLabel = {c:k for k,c in labelDict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=df.intent.map(labelDict)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textlen']=df['instruction'].str.len()\n",
    "print(df.textlen.describe())\n",
    "df.drop(\"textlen\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def slugOrderNumber(s,t ='{{Order Number}}' ):\n",
    "    oNum = str(random.randint(100,1000000))+'-'+str(random.randint(100,1000000))\n",
    "    ss=re.sub(t,oNum,s)\n",
    "    return ss\n",
    "\n",
    "def slugInvoiceNumber(s,t ='{{Invoice Number}}' ):\n",
    "    oNum = str(random.randint(100,1000000))+'-'+str(random.randint(100,1000000))\n",
    "    ss=re.sub(t,oNum,s)\n",
    "    return ss\n",
    "\n",
    "def slugRefundAmount(s,t ='{{Refund Amount}}' ):\n",
    "    oNum = str(round(random.uniform(5.,250),2))\n",
    "    ss=re.sub(t,oNum,s)\n",
    "    return ss\n",
    "\n",
    "def slugMoneyAmount(s,t ='{{Money Amount}}' ):\n",
    "    oNum = str(round(random.uniform(5.,250),2))\n",
    "    ss=re.sub(t,oNum,s)\n",
    "    return ss\n",
    "\n",
    "def slugDeliveryCity(s,t ='{{Delivery City}}' ):\n",
    "    newCity = random.choice(city_names)\n",
    "    ss=re.sub(t,newCity,s)\n",
    "    return ss\n",
    "\n",
    "def slugDeliveryCountry(s,t ='{{Delivery Country}}' ):\n",
    "    newCountry = random.choice(country_names)\n",
    "    ss=re.sub(t,newCountry,s)\n",
    "    return ss\n",
    "\n",
    "def slugDeliveryAccountType(s,t ='{{Account Type}}' ):\n",
    "    newAccount = random.choice(accounts)\n",
    "    ss=re.sub(t,newAccount,s)\n",
    "    return ss\n",
    "\n",
    "def slugDeliveryAccountCategory(s,t ='{{Account Category}}' ):\n",
    "    newAccount = random.choice(accounts)\n",
    "    ss=re.sub(t,newAccount,s)\n",
    "    return ss\n",
    "\n",
    "def slugCurrencySymbol(s,t ='{{Currency Symbol}}' ):\n",
    "    newCurrency = random.choice(currency_symbols)\n",
    "    ss=re.sub(t,newCurrency,s)\n",
    "    return ss\n",
    "\n",
    "def slugPersonName(s,t ='{{Person Name}}' ):\n",
    "    fName = random.choice(first_names)\n",
    "    lName = random.choice(last_names)\n",
    "    ss=re.sub(t,fName+' '+lName,s)\n",
    "    return ss\n",
    "\n",
    "dataFunctions = ['slugOrderNumber',\n",
    " 'slugInvoiceNumber',\n",
    " 'slugRefundAmount',\n",
    " 'slugMoneyAmount',\n",
    " 'slugDeliveryCity',\n",
    " 'slugDeliveryCountry',\n",
    " 'slugDeliveryAccountType',\n",
    " 'slugDeliveryAccountCategory',\n",
    " 'slugCurrencySymbol',\n",
    " 'slugPersonName']\n",
    "\n",
    "for f in dataFunctions:\n",
    "    df['instruction']=df['instruction'].apply(locals()[f])\n",
    "\n",
    "targetsToFill = df.instruction.str.extract(r'\\{\\{([^}]*)\\}\\}')\n",
    "unique_targets = targetsToFill.value_counts()\n",
    "if len(unique_targets)==0:\n",
    "    print(\"Great! All targets are filled with data\")\n",
    "else:\n",
    "    print(\"Still need to fix these!\")\n",
    "    print(unique_targets.head(20))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.sample(n=1300,replace=False,random_state=42)\n",
    "\n",
    "df_train, df_test  = train_test_split(df, test_size=0.33, random_state=42)\n",
    "if tinyTest:\n",
    "    df_train, junk  = train_test_split(df_train, test_size=0.99, random_state=42)\n",
    "df_test, df_val  = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "if tinyTest:\n",
    "    df_test, junk  = train_test_split(df_test, test_size=0.99, random_state=42)\n",
    "    df_val, junk  = train_test_split(df_val, test_size=0.99, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)\n",
    "val_dataset = Dataset.from_pandas(df_val)\n",
    "\n",
    "print(len(train_dataset),len(test_dataset),len(val_dataset))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"instruction\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "#tokenized_val= val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(modelName, num_labels=len(labelDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
    "\n",
    "if tinyTest:\n",
    "    training_args.num_epochs=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args.num_train_epochs=10\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score the full test, then run a labeled confusion matrix\n",
    "#Use existing model to gauge sentiment - do a dist vs. actual and pred labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"custServiceClassifier\" not in os.listdir():\n",
    "    os.mkdir(\"custServiceClassifier\")\n",
    "    \n",
    "trainer.save_model(\"custServiceClassifier/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "clf = pipeline(\"text-classification\", model,tokenizer =modelName )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=clf.predict(val_dataset['instruction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(z)\n",
    "y.columns = ['predTxt','score']\n",
    "y['true']=val_dataset['label']\n",
    "#y['pred']=y.predTxt.str[6:].astype(int)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_score(y.pred,y.true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 25)\n",
    "cm=pd.DataFrame(confusion_matrix(y.pred,y.true,normalize='true')).round(1)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)\n",
    "\n",
    "sns.heatmap(cm, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label=reverseLabel\n",
    "model.push_to_hub(\"custServiceClassifier\")\n",
    "\n",
    "clf = pipeline(\"text-classification\", model,tokenizer =modelName )\n",
    "\n",
    "clf.predict(\"Hey, I'm really pissed. What's the status of getting my money back?  You guys screwed it up royally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
